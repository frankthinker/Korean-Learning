#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ©è¯­ç»ƒä¹ é¢˜æå–è„šæœ¬ - ä¿®å¤ç‰ˆæœ¬
- ä»practiceDatabase.jsä¸­ç²¾ç¡®æå–æ¯ä¸ªè¯­æ³•ç‚¹
- è°ƒæ•´ç¼©è¿›ä¸º2ç©ºæ ¼ï¼Œæ ¼å¼ä¸beg_001.jsä¿æŒä¸€è‡´
"""

import os
import re

# å®šä¹‰æ‰€æœ‰åˆçº§è¯­æ³•ç‚¹
BEGINNER_GRAMMARS = [
    {'id': 'beg_005', 'start': 542, 'end': 673},
    {'id': 'beg_006', 'start': 675, 'end': 771},
    {'id': 'beg_007', 'start': 773, 'end': 874},
    {'id': 'beg_008', 'start': 876, 'end': 972},
    {'id': 'beg_009', 'start': 974, 'end': 1070},
]

INTERMEDIATE_GRAMMARS = [
    {'id': 'int_001', 'start': 1075, 'end': 1180},
    {'id': 'int_002', 'start': 1181, 'end': 1286},
    {'id': 'int_003', 'start': 1287, 'end': 1392},
    {'id': 'int_004', 'start': 1393, 'end': 1498},
    {'id': 'int_005', 'start': 1499, 'end': 1604},
    {'id': 'int_006', 'start': 1605, 'end': 1710},
    {'id': 'int_007', 'start': 1711, 'end': 1816},
    {'id': 'int_008', 'start': 1817, 'end': 1922},
    {'id': 'int_009', 'start': 1923, 'end': 2054},
    {'id': 'int_010', 'start': 2055, 'end': 2183},
    {'id': 'int_011', 'start': 2184, 'end': 2309},
    {'id': 'int_012', 'start': 2310, 'end': 2435},
    {'id': 'int_013', 'start': 2436, 'end': 2437},
    {'id': 'int_014', 'start': 2438, 'end': 2439},
    {'id': 'int_015', 'start': 2440, 'end': 2441},
    {'id': 'int_016', 'start': 2442, 'end': 2443},
    {'id': 'int_017', 'start': 2444, 'end': 2445},
    {'id': 'int_018', 'start': 2446, 'end': 2437},
]

ADVANCED_GRAMMARS = [
    {'id': 'adv_001', 'start': 2440, 'end': 2541},
    {'id': 'adv_002', 'start': 2542, 'end': 2643},
    {'id': 'adv_003', 'start': 2644, 'end': 2705},
    {'id': 'adv_004', 'start': 2706, 'end': 2774},
    {'id': 'adv_005', 'start': 2775, 'end': 2843},
    {'id': 'adv_006', 'start': 2844, 'end': 2911},
    {'id': 'adv_007', 'start': 2912, 'end': 2979},
    {'id': 'adv_008', 'start': 2980, 'end': 3047},
    {'id': 'adv_009', 'start': 3048, 'end': 3115},
    {'id': 'adv_010', 'start': 3116, 'end': 3183},
    {'id': 'adv_011', 'start': 3184, 'end': 3185},
    {'id': 'adv_012', 'start': 3186, 'end': 3187},
    {'id': 'adv_013', 'start': 3188, 'end': 3189},
    {'id': 'adv_014', 'start': 3190, 'end': 3191},
    {'id': 'adv_015', 'start': 3192, 'end': 3193},
    {'id': 'adv_016', 'start': 3194, 'end': 3195},
    {'id': 'adv_017', 'start': 3196, 'end': 3197},
]


def extract_grammar_point(file_path, start_line, end_line):
    """ä»åŸå§‹æ–‡ä»¶ä¸­æå–ç‰¹å®šè¡ŒèŒƒå›´çš„å†…å®¹"""
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # æå–æŒ‡å®šèŒƒå›´çš„è¡Œï¼ˆè¡Œå·æ˜¯1-basedçš„ï¼‰
    extracted_lines = lines[start_line - 1:end_line]
    
    return extracted_lines


def adjust_indentation(lines):
    """è°ƒæ•´ç¼©è¿›ï¼šåŸæ–‡4ç©ºæ ¼â†’2ç©ºæ ¼ï¼Œç§»é™¤ç¬¬ä¸€è¡Œçš„è¯­æ³•ç‚¹æ ‡è®°ä»¥åŠæœ€åçš„ç©ºè¡Œå’Œé€—å·"""
    output_lines = []
    
    for i, line in enumerate(lines):
        # ç¬¬ä¸€è¡ŒåŒ…å« 'beg_008: [' çš„å½¢å¼ï¼Œéœ€è¦è·³è¿‡
        if i == 0:
            continue
        
        # åºæ•°å€™ä¸€è¡Œæ˜¯éœ€è¦ç§»é™¤çš„ '],' æ±¡æŸ“
        if i == len(lines) - 2 and line.strip() == '],':  # åºæ•°å€™ä¸€è¡Œæ˜¯â€˜],â€™ï¼ˆå¯èƒ½æœ‰å­”æ´Ÿï¼‰
            continue
        
        # æœ€åä¸€è¡Œæ˜¯ç©ºè¡Œï¼Œè·³è¿‡
        if i == len(lines) - 1:
            continue
        
        # è°ƒæ•´ç¼©è¿›ï¼šåŸæ–‡ 4 ç©ºæ ¼ â†’ 2 ç©ºæ ¼
        if line.startswith('      '):  # 6ç©ºæ ¼å˜4ç©ºæ ¼
            output_lines.append('    ' + line[6:])
        elif line.startswith('    '):  # 4ç©ºæ ¼å˜2ç©ºæ ¼
            output_lines.append('  ' + line[4:])
        elif line.startswith('  '):   # 2ç©ºæ ¼ä¿æŒ
            output_lines.append(line)
        else:
            output_lines.append(line)
    
    return output_lines


def process_extracted_content(lines, grammar_id):
    """å¤„ç†æå–çš„å†…å®¹ï¼Œè½¬æ¢ä¸ºç‹¬ç«‹æ–‡ä»¶æ ¼å¼"""
    # ç¬¬ä¸€è¡Œæ˜¯è¯­æ³•ç‚¹å®šä¹‰ï¼Œéœ€è¦æå–æ³¨é‡Š
    first_line = lines[0]
    
    # æå–æ³¨é‡Šéƒ¨åˆ†
    comment_match = re.search(r'//\s*(.*)', first_line)
    comment = comment_match.group(1).strip() if comment_match else grammar_id
    
    # è°ƒæ•´ç¼©è¿›
    adjusted_lines = adjust_indentation(lines)
    
    # æ„å»ºæ–°æ–‡ä»¶å†…å®¹
    output_lines = []
    output_lines.append(f"// {comment} ç»ƒä¹ é¢˜\n")
    output_lines.append(f"export const practice_{grammar_id} = [\n")
    
    # æ·»åŠ è°ƒæ•´åçš„å†…å®¹è¡Œ
    for line in adjusted_lines:
        output_lines.append(line)
    
    # æ·»åŠ ç»“æŸç¬¦
    output_lines.append("];\n")
    
    return output_lines


def write_practice_file(grammar_id, content_lines, level):
    """å°†å†…å®¹å†™å…¥æ–‡ä»¶"""
    output_dir = f"src/data/practice/{level}"
    os.makedirs(output_dir, exist_ok=True)
    
    file_path = os.path.join(output_dir, f"{grammar_id}.js")
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.writelines(content_lines)
    
    return file_path


def main():
    input_file = "src/data/practiceDatabase.js"
    
    print("ğŸš€ å¼€å§‹æå–ç»ƒä¹ é¢˜ï¼ˆä¿®å¤ç¼©è¿›ï¼‰...\n")
    
    # å¤„ç†åˆçº§è¯­æ³•
    print("ğŸ“š åˆçº§è¯­æ³•ç‚¹ (beg_005-beg_009):")
    for grammar in BEGINNER_GRAMMARS:
        grammar_id = grammar['id']
        start = grammar['start']
        end = grammar['end']
        
        # æå–å†…å®¹
        lines = extract_grammar_point(input_file, start, end)
        
        # å¤„ç†å†…å®¹
        content_lines = process_extracted_content(lines, grammar_id)
        
        # å†™å…¥æ–‡ä»¶
        file_path = write_practice_file(grammar_id, content_lines, 'beginner')
        
        # è®¡ç®—é¢˜ç›®æ•°é‡
        question_count = sum(1 for line in content_lines if "id: '" in line and "_" in line)
        print(f"  âœ… {grammar_id}: {question_count} é“é¢˜ â†’ {file_path}")
    
    print()
    print("ğŸ“š ä¸­çº§è¯­æ³•ç‚¹ (int_001-int_018):")
    for grammar in INTERMEDIATE_GRAMMARS:
        grammar_id = grammar['id']
        start = grammar['start']
        end = grammar['end']
        
        # æå–å†…å®¹
        lines = extract_grammar_point(input_file, start, end)
        
        # å¤„ç†å†…å®¹
        content_lines = process_extracted_content(lines, grammar_id)
        
        # å†™å…¥æ–‡ä»¶
        file_path = write_practice_file(grammar_id, content_lines, 'intermediate')
        
        # è®¡ç®—é¢˜ç›®æ•°é‡
        question_count = sum(1 for line in content_lines if "id: '" in line and "_" in line)
        print(f"  âœ… {grammar_id}: {question_count} é“é¢˜ â†’ {file_path}")
    
    print()
    print("ğŸ“š é«˜çº§è¯­æ³•ç‚¹ (adv_001-adv_017):")
    for grammar in ADVANCED_GRAMMARS:
        grammar_id = grammar['id']
        start = grammar['start']
        end = grammar['end']
        
        # æå–å†…å®¹
        lines = extract_grammar_point(input_file, start, end)
        
        # å¤„ç†å†…å®¹
        content_lines = process_extracted_content(lines, grammar_id)
        
        # å†™å…¥æ–‡ä»¶
        file_path = write_practice_file(grammar_id, content_lines, 'advanced')
        
        # è®¡ç®—é¢˜ç›®æ•°é‡
        question_count = sum(1 for line in content_lines if "id: '" in line and "_" in line)
        print(f"  âœ… {grammar_id}: {question_count} é“é¢˜ â†’ {file_path}")
    
    print()
    print("ğŸ‰ å…¨éƒ¨æå–å®Œæˆï¼")


if __name__ == "__main__":
    main()
