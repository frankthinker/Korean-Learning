#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ›´å¥½çš„ç»ƒä¹ æ•°æ®æå–è„šæœ¬
- ç²¾ç¡®æå–å®Œæ•´çš„è¯­æ³•ç‚¹å†…å®¹
- ä¿æŒåŽŸæœ‰æ ¼å¼å’Œå†…å®¹ä¸å˜
"""

import re
import os

def extract_complete_grammar_point(file_path, target_grammar_id):
    """æå–å®Œæ•´çš„è¯­æ³•ç‚¹å†…å®¹"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ‰¾åˆ°beginneréƒ¨åˆ†
    beginner_start = content.find('beginner: {')
    if beginner_start == -1:
        return None
    
    # æ‰¾åˆ°ä¸‹ä¸€ä¸ªéƒ¨åˆ†æˆ–æ–‡ä»¶ç»“å°¾
    intermediate_start = content.find('intermediate:', beginner_start)
    advanced_start = content.find('advanced:', beginner_start)
    
    # ç¡®å®šç»“æŸä½ç½®
    end_pos = len(content)
    if intermediate_start != -1:
        end_pos = min(end_pos, intermediate_start)
    if advanced_start != -1:
        end_pos = min(end_pos, advanced_start)
    
    # æå–åˆçº§éƒ¨åˆ†
    beginner_content = content[beginner_start:end_pos]
    
    # æ‰¾åˆ°ç›®æ ‡è¯­æ³•ç‚¹çš„å¼€å§‹ä½ç½®
    grammar_start_pattern = f'{target_grammar_id}: \\['
    grammar_start = beginner_content.find(grammar_start_pattern)
    if grammar_start == -1:
        return None
    
    # ä»Žè¯­æ³•ç‚¹å¼€å§‹ä½ç½®å‘åŽæŸ¥æ‰¾ï¼Œç›´åˆ°æ‰¾åˆ°ç»“æŸæ‹¬å·
    # éœ€è¦æ­£ç¡®å¤„ç†åµŒå¥—çš„æ‹¬å·
    start_pos = grammar_start + len(grammar_start_pattern)
    
    # æ‰¾åˆ°åŒ¹é…çš„å³æ‹¬å·
    bracket_count = 1  # å·²ç»æœ‰ä¸€ä¸ªå·¦æ‹¬å·
    pos = start_pos
    
    while bracket_count > 0 and pos < len(beginner_content):
        if beginner_content[pos] == '[':
            bracket_count += 1
        elif beginner_content[pos] == ']':
            bracket_count -= 1
        pos += 1
    
    if bracket_count != 0:
        return None  # æ‹¬å·ä¸åŒ¹é…
    
    # æå–å®Œæ•´å†…å®¹
    grammar_content = beginner_content[grammar_start:pos]
    return grammar_content

def convert_to_export_format(grammar_id, original_content):
    """è½¬æ¢ä¸ºå¯¼å‡ºæ ¼å¼"""
    # æå–æ³¨é‡Š
    comment_match = re.search(r'\/\/(.*)', original_content)
    comment = comment_match.group(1).strip() if comment_match else grammar_id
    
    # æ›¿æ¢è¯­æ³•ç‚¹å®šä¹‰ä¸ºå¯¼å‡ºæ ¼å¼
    # åŒ¹é…ç±»ä¼¼ "beg_001: [ // æ³¨é‡Š" çš„æ¨¡å¼
    pattern = rf'{grammar_id}: \['
    export_content = re.sub(pattern, f"// {comment} ç»ƒä¹ é¢˜\nexport const practice_{grammar_id} = [", original_content, 1)
    
    return export_content

def create_practice_file(grammar_id, content, output_dir):
    """åˆ›å»ºç»ƒä¹ æ–‡ä»¶"""
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # å†™å…¥æ–‡ä»¶
    file_path = os.path.join(output_dir, f"{grammar_id}.js")
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = len(f.readlines())
    
    print(f"âœ… å·²åˆ›å»ºæ–‡ä»¶: {file_path} ({lines} è¡Œ)")

def create_index_file(grammar_ids, output_dir):
    """åˆ›å»ºç´¢å¼•æ–‡ä»¶"""
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    index_content = "// åˆçº§è¯­æ³•ç»ƒä¹ é¢˜ç´¢å¼•æ–‡ä»¶\n"
    
    # æ·»åŠ å¯¼å…¥è¯­å¥
    for grammar_id in grammar_ids:
        index_content += f"import {{ practice_{grammar_id} }} from './{grammar_id}.js';\n"
    
    index_content += "\n"
    index_content += "export const beginnerPracticeDatabase = {\n"
    
    # æ·»åŠ å¯¼å‡ºè¯­å¥
    for grammar_id in grammar_ids:
        index_content += f"  {grammar_id}: practice_{grammar_id},\n"
    
    index_content += "};\n"
    
    # å†™å…¥ç´¢å¼•æ–‡ä»¶
    index_path = os.path.join(output_dir, "index.js")
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write(index_content)
    
    print(f"âœ… å·²åˆ›å»ºç´¢å¼•æ–‡ä»¶: {index_path}")

def main():
    print("ðŸš€ å¼€å§‹æ›´å¥½çš„ç»ƒä¹ æ•°æ®æå–...")
    
    # è¾“å…¥æ–‡ä»¶è·¯å¾„
    input_file = "src/data/practiceDatabase.js"
    
    # è¾“å‡ºç›®å½•
    output_dir = "src/data/practice/beginner"
    
    # å®šä¹‰æ‰€æœ‰åˆçº§è¯­æ³•ç‚¹
    grammar_ids = [
        'beg_001', 'beg_002', 'beg_003', 'beg_004', 
        'beg_005', 'beg_006', 'beg_007', 'beg_008', 'beg_009'
    ]
    
    print(f"ðŸ“Š å¤„ç† {len(grammar_ids)} ä¸ªè¯­æ³•ç‚¹")
    
    # ä¸ºæ¯ä¸ªè¯­æ³•ç‚¹åˆ›å»ºæ–‡ä»¶
    created_files = []
    for grammar_id in grammar_ids:
        print(f"ðŸ“ æå–è¯­æ³•ç‚¹ {grammar_id}...")
        content = extract_complete_grammar_point(input_file, grammar_id)
        
        if content:
            # è½¬æ¢ä¸ºå¯¼å‡ºæ ¼å¼
            export_content = convert_to_export_format(grammar_id, content)
            
            # åˆ›å»ºæ–‡ä»¶
            create_practice_file(grammar_id, export_content, output_dir)
            created_files.append(grammar_id)
        else:
            print(f"âŒ æœªæ‰¾åˆ°è¯­æ³•ç‚¹ {grammar_id}")
    
    # åˆ›å»ºç´¢å¼•æ–‡ä»¶
    if created_files:
        create_index_file(created_files, output_dir)
    
    print(f"ðŸŽ‰ æ›´å¥½çš„æå–å®Œæˆï¼æˆåŠŸåˆ›å»º {len(created_files)} ä¸ªæ–‡ä»¶")

if __name__ == "__main__":
    main()