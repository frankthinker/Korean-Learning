#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ©è¯­ç»ƒä¹ é¢˜æå–è„šæœ¬
- ä»practiceDatabase.jsä¸­ç²¾ç¡®æå–æ¯ä¸ªè¯­æ³•ç‚¹
- åˆ›å»ºç‹¬ç«‹çš„JSæ–‡ä»¶ï¼Œæ ¼å¼ä¸beg_001.jsä¿æŒä¸€è‡´
"""

import os
import re

# å®šä¹‰æ‰€æœ‰åˆçº§è¯­æ³•ç‚¹ï¼ˆå·²éªŒè¯æ ¼å¼æ­£ç¡®çš„æ˜¯beg_001-004ï¼‰
BEGINNER_GRAMMARS = [
    {'id': 'beg_005', 'start': 542, 'end': 674},
    {'id': 'beg_006', 'start': 675, 'end': 772},
    {'id': 'beg_007', 'start': 773, 'end': 875},
    {'id': 'beg_008', 'start': 876, 'end': 973},
    {'id': 'beg_009', 'start': 974, 'end': 1074},
]

INTERMEDIATE_GRAMMARS = [
    {'id': 'int_001', 'start': 1075, 'end': 1180},
    {'id': 'int_002', 'start': 1181, 'end': 1286},
    {'id': 'int_003', 'start': 1287, 'end': 1392},
    {'id': 'int_010', 'start': 1393, 'end': 1498},
    {'id': 'int_011', 'start': 1499, 'end': 1604},
    {'id': 'int_012', 'start': 1605, 'end': 1710},
    {'id': 'int_013', 'start': 1711, 'end': 1816},
    {'id': 'int_014', 'start': 1817, 'end': 1922},
    {'id': 'int_015', 'start': 1923, 'end': 2054},
    {'id': 'int_016', 'start': 2055, 'end': 2183},
    {'id': 'int_017', 'start': 2184, 'end': 2309},
    {'id': 'int_018', 'start': 2310, 'end': 2439},
]

ADVANCED_GRAMMARS = [
    {'id': 'adv_001', 'start': 2440, 'end': 2541},
    {'id': 'adv_002', 'start': 2542, 'end': 2643},
    {'id': 'adv_010', 'start': 2644, 'end': 2705},
    {'id': 'adv_011', 'start': 2706, 'end': 2774},
    {'id': 'adv_012', 'start': 2775, 'end': 2843},
    {'id': 'adv_013', 'start': 2844, 'end': 2911},
    {'id': 'adv_014', 'start': 2912, 'end': 2979},
    {'id': 'adv_015', 'start': 2980, 'end': 3047},
    {'id': 'adv_016', 'start': 3048, 'end': 3115},
    {'id': 'adv_017', 'start': 3116, 'end': 3185},
]


def extract_grammar_point(file_path, start_line, end_line):
    """ä»åŸå§‹æ–‡ä»¶ä¸­æå–ç‰¹å®šè¡ŒèŒƒå›´çš„å†…å®¹"""
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # æå–æŒ‡å®šèŒƒå›´çš„è¡Œï¼ˆè¡Œå·æ˜¯1-basedçš„ï¼‰
    extracted_lines = lines[start_line - 1:end_line]
    
    return extracted_lines


def process_extracted_content(lines, grammar_id):
    """å¤„ç†æå–çš„å†…å®¹ï¼Œè½¬æ¢ä¸ºç‹¬ç«‹æ–‡ä»¶æ ¼å¼"""
    # ç¬¬ä¸€è¡Œæ˜¯è¯­æ³•ç‚¹å®šä¹‰ï¼Œéœ€è¦æå–æ³¨é‡Š
    first_line = lines[0]
    
    # æå–æ³¨é‡Šéƒ¨åˆ†
    comment_match = re.search(r'//\s*(.*)', first_line)
    comment = comment_match.group(1).strip() if comment_match else grammar_id
    
    # æ„å»ºæ–°æ–‡ä»¶å†…å®¹
    output_lines = []
    output_lines.append(f"// {comment} ç»ƒä¹ é¢˜\n")
    output_lines.append(f"export const practice_{grammar_id} = [\n")
    
    # æ·»åŠ ä¸­é—´çš„å†…å®¹è¡Œï¼ˆè·³è¿‡ç¬¬ä¸€è¡Œå’Œæœ€åä¸€è¡Œï¼‰
    for line in lines[1:-1]:
        output_lines.append(line)
    
    # æ·»åŠ ç»“æŸç¬¦ï¼ˆç§»é™¤æœ€åä¸€è¡Œå¯èƒ½çš„é€—å·ï¼‰
    output_lines.append("];\n")
    
    # ç§»é™¤å€’æ•°ç¬¬äºŒè¡Œçš„å¤šä½™é€—å·ï¼ˆå¦‚æœæœ€åæ˜¯ ],  çš„è¯ï¼‰
    if len(output_lines) >= 2:
        last_content = output_lines[-2].rstrip()
        if last_content.endswith('],'):
            output_lines[-2] = last_content[:-1] + '\n'
    
    return output_lines


def write_practice_file(grammar_id, content_lines, level):
    """å°†å†…å®¹å†™å…¥æ–‡ä»¶"""
    output_dir = f"src/data/practice/{level}"
    os.makedirs(output_dir, exist_ok=True)
    
    file_path = os.path.join(output_dir, f"{grammar_id}.js")
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.writelines(content_lines)
    
    return file_path


def main():
    input_file = "src/data/practiceDatabase.js"
    
    print("ğŸš€ å¼€å§‹æå–ç»ƒä¹ é¢˜...")
    print()
    
    # å¤„ç†åˆçº§è¯­æ³•
    print("ğŸ“š åˆçº§è¯­æ³•ç‚¹ (beg_005-beg_009):")
    for grammar in BEGINNER_GRAMMARS:
        grammar_id = grammar['id']
        start = grammar['start']
        end = grammar['end']
        
        # æå–å†…å®¹
        lines = extract_grammar_point(input_file, start, end)
        
        # å¤„ç†å†…å®¹
        content_lines = process_extracted_content(lines, grammar_id)
        
        # å†™å…¥æ–‡ä»¶
        file_path = write_practice_file(grammar_id, content_lines, 'beginner')
        
        # è®¡ç®—é¢˜ç›®æ•°é‡
        question_count = sum(1 for line in content_lines if "id: 'beg_" in line)
        print(f"  âœ… {grammar_id}: {question_count} é“é¢˜ â†’ {file_path}")
    
    print()
    print("ğŸ“š ä¸­çº§è¯­æ³•ç‚¹ (int_001-int_018):")
    for grammar in INTERMEDIATE_GRAMMARS:
        grammar_id = grammar['id']
        start = grammar['start']
        end = grammar['end']
        
        # æå–å†…å®¹
        lines = extract_grammar_point(input_file, start, end)
        
        # å¤„ç†å†…å®¹
        content_lines = process_extracted_content(lines, grammar_id)
        
        # å†™å…¥æ–‡ä»¶
        file_path = write_practice_file(grammar_id, content_lines, 'intermediate')
        
        # è®¡ç®—é¢˜ç›®æ•°é‡
        question_count = sum(1 for line in content_lines if f"id: '{grammar_id}_" in line)
        print(f"  âœ… {grammar_id}: {question_count} é“é¢˜ â†’ {file_path}")
    
    print()
    print("ğŸ“š é«˜çº§è¯­æ³•ç‚¹ (adv_001-adv_017):")
    for grammar in ADVANCED_GRAMMARS:
        grammar_id = grammar['id']
        start = grammar['start']
        end = grammar['end']
        
        # æå–å†…å®¹
        lines = extract_grammar_point(input_file, start, end)
        
        # å¤„ç†å†…å®¹
        content_lines = process_extracted_content(lines, grammar_id)
        
        # å†™å…¥æ–‡ä»¶
        file_path = write_practice_file(grammar_id, content_lines, 'advanced')
        
        # è®¡ç®—é¢˜ç›®æ•°é‡
        question_count = sum(1 for line in content_lines if f"id: '{grammar_id}_" in line)
        print(f"  âœ… {grammar_id}: {question_count} é“é¢˜ â†’ {file_path}")
    
    print()
    print("ğŸ‰ å…¨éƒ¨æå–å®Œæˆï¼")


if __name__ == "__main__":
    main()
